{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# tff.federated_computation(lambda: 'Hello, World!')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3383"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emnist_train.client_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('label', TensorSpec(shape=(), dtype=tf.int32, name=None)),\n",
       "             ('pixels',\n",
       "              TensorSpec(shape=(28, 28), dtype=tf.float32, name=None))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emnist_train.element_type_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_dataset = emnist_train.create_tf_dataset_for_client(\n",
    "    emnist_train.client_ids[0])\n",
    "\n",
    "example_element = next(iter(example_dataset))\n",
    "\n",
    "example_element['label'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(example_element['pixels'].numpy(), cmap='gray', aspect='equal')\n",
    "plt.grid(False)\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 10\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 20\n",
    "SHUFFLE_BUFFER = 100\n",
    "PREFETCH_BUFFER=10\n",
    "\n",
    "def preprocess(dataset):\n",
    "\n",
    "  def batch_format_fn(element):\n",
    "    \"\"\"Flatten a batch `pixels` and return the features as an `OrderedDict`.\"\"\"\n",
    "    return collections.OrderedDict(\n",
    "        x=tf.reshape(element['pixels'], [-1, 784]),\n",
    "        y=tf.reshape(element['label'], [-1, 1]))\n",
    "\n",
    "  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(\n",
    "      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('x',\n",
       "              array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "                     [1., 1., 1., ..., 1., 1., 1.],\n",
       "                     [1., 1., 1., ..., 1., 1., 1.],\n",
       "                     ...,\n",
       "                     [1., 1., 1., ..., 1., 1., 1.],\n",
       "                     [1., 1., 1., ..., 1., 1., 1.],\n",
       "                     [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)),\n",
       "             ('y',\n",
       "              array([[6],\n",
       "                     [7],\n",
       "                     [8],\n",
       "                     [9],\n",
       "                     [4],\n",
       "                     [9],\n",
       "                     [7],\n",
       "                     [4],\n",
       "                     [7],\n",
       "                     [4],\n",
       "                     [3],\n",
       "                     [3],\n",
       "                     [6],\n",
       "                     [2],\n",
       "                     [7],\n",
       "                     [3],\n",
       "                     [7],\n",
       "                     [0],\n",
       "                     [8],\n",
       "                     [5]], dtype=int32))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_example_dataset = preprocess(example_dataset)\n",
    "\n",
    "sample_batch = tf.nest.map_structure(lambda x: x.numpy(),\n",
    "                                     next(iter(preprocessed_example_dataset)))\n",
    "\n",
    "sample_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_federated_data(client_data, client_ids):\n",
    "  return [\n",
    "      preprocess(client_data.create_tf_dataset_for_client(x))\n",
    "      for x in client_ids\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of client datasets: 10\n",
      "First dataset: <PrefetchDataset shapes: OrderedDict([(x, (None, 784)), (y, (None, 1))]), types: OrderedDict([(x, tf.float32), (y, tf.int32)])>\n"
     ]
    }
   ],
   "source": [
    "sample_clients = emnist_train.client_ids[0:NUM_CLIENTS]\n",
    "\n",
    "federated_train_data = make_federated_data(emnist_train, sample_clients)\n",
    "\n",
    "print('Number of client datasets: {l}'.format(l=len(federated_train_data)))\n",
    "print('First dataset: {d}'.format(d=federated_train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Input(shape=(784,)),\n",
    "      tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n",
    "      tf.keras.layers.Softmax(),\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "  # We _must_ create a new model here, and _not_ capture it from an external\n",
    "  # scope. TFF will call this within different graph contexts.\n",
    "  keras_model = create_keras_model()\n",
    "  return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      input_spec=preprocessed_example_dataset.element_spec,\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/y0v005b/Learning/tf-federated/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "iterative_process = tff.learning.build_federated_averaging_process(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'( -> <model=<trainable=<float32[784,10],float32[10]>,non_trainable=<>>,optimizer_state=<int64>,delta_aggregate_state=<>,model_broadcast_state=<>>@SERVER)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(iterative_process.initialize.type_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  1, metrics=<sparse_categorical_accuracy=0.11255144327878952,loss=3.123215913772583,keras_training_time_client_sum_sec=0.0>\n"
     ]
    }
   ],
   "source": [
    "state, metrics = iterative_process.next(state, federated_train_data)\n",
    "print('round  1, metrics={}'.format(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  2, metrics=<sparse_categorical_accuracy=0.13477365672588348,loss=3.001572847366333,keras_training_time_client_sum_sec=0.0>\n",
      "round  3, metrics=<sparse_categorical_accuracy=0.14835390448570251,loss=2.8244476318359375,keras_training_time_client_sum_sec=0.0>\n",
      "round  4, metrics=<sparse_categorical_accuracy=0.15925925970077515,loss=2.8203494548797607,keras_training_time_client_sum_sec=0.0>\n",
      "round  5, metrics=<sparse_categorical_accuracy=0.19156378507614136,loss=2.545574903488159,keras_training_time_client_sum_sec=0.0>\n",
      "round  6, metrics=<sparse_categorical_accuracy=0.21111111342906952,loss=2.5024778842926025,keras_training_time_client_sum_sec=0.0>\n",
      "round  7, metrics=<sparse_categorical_accuracy=0.22860082983970642,loss=2.355034112930298,keras_training_time_client_sum_sec=0.0>\n",
      "round  8, metrics=<sparse_categorical_accuracy=0.26687243580818176,loss=2.2404472827911377,keras_training_time_client_sum_sec=0.0>\n",
      "round  9, metrics=<sparse_categorical_accuracy=0.3127571940422058,loss=2.1505444049835205,keras_training_time_client_sum_sec=0.0>\n",
      "round 10, metrics=<sparse_categorical_accuracy=0.3302469253540039,loss=2.0094780921936035,keras_training_time_client_sum_sec=0.0>\n"
     ]
    }
   ],
   "source": [
    "NUM_ROUNDS = 11\n",
    "for round_num in range(2, NUM_ROUNDS):\n",
    "  state, metrics = iterative_process.next(state, federated_train_data)\n",
    "  print('round {:2d}, metrics={}'.format(round_num, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"/tmp/logs/scalars/training/\"\n",
    "summary_writer = tf.summary.create_file_writer(logdir)\n",
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
